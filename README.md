# XGBoost Anomaly Detection on UNSW-NB15 Dataset

This project applies the XGBoost algorithm for anomaly detection using the **UNSW-NB15 dataset**, a modern labeled dataset built for network intrusion detection research. It demonstrates how a machine learning model can effectively detect attacks in **highly imbalanced data**, where traditional accuracy can be misleading.

---

## ğŸ“ Datasets Used

The dataset consists of **four raw CSV files**:

- `UNSW-NB15_1.csv`
- `UNSW-NB15_2.csv`
- `UNSW-NB15_3.csv`
- `UNSW-NB15_4.csv`

Each file contains labeled network flow records (totaling over 2 million), including:

- IP addresses, ports, byte counts
- Duration, protocol types, service flags
- Labels: "Normal" vs specific attack types (e.g., DoS, Exploits, Worms)

These files are split for collection purposes but are structurally identical.

---

## ğŸ”„ Data Preprocessing

The script `src/preprocess.py` performs the following pipeline:

1. **Combines** all four CSV files into a single dataset.
2. **Cleans** rows with missing or corrupted values.
3. **Encodes** categorical features using label encoding.
4. **Normalizes** continuous numeric features.
5. Saves the result as:  
   â¤ `data/processed/combined_cleaned.csv`

This final dataset is used for training and evaluation.

---

## âš™ï¸ Model: XGBoost

We use **XGBoost**, a gradient-boosted decision tree algorithm known for its high performance on structured/tabular data.

---

## ğŸ“Š XGBoost Results

| Metric        | Value     |
|---------------|-----------|
| **Accuracy**  | 41.27%    |
| **Precision** | 79.54%    |
| **Recall**    | 83.69%    |
| **F1 Score**  | 81.56%    |
| **AUC-ROC**   | 90.12%    |

---

## ğŸ¤” Why F1 Score Matters More Than Accuracy

This project deals with a **class-imbalanced problem** â€” the dataset contains **far more normal network traffic** than malicious activity. In such cases:

- **Accuracy is misleading**:
  > A model can be 95% "accurate" by always predicting **"normal"**, yet it may completely miss actual attacks.

- **Precision** tells us: *Of all predicted attacks, how many were real?*
- **Recall** tells us: *Of all actual attacks, how many did we catch?*
- **F1 Score** balances these â€” itâ€™s the harmonic mean of precision and recall.

In **intrusion detection**, this matters greatly:
- Missing an attack (false negative) can be **catastrophic**
- Flagging some false positives is acceptable if real threats are caught

---

## ğŸ§  What Our Model Achieved

Despite **low accuracy** (41.27%) â€” expected due to imbalance â€” our model:

- Correctly caught **most real attacks** (recall = 83.69%)
- Made **very few false attack predictions** (precision = 79.54%)
- Balanced performance with an **F1-score of 81.56%**
- Scored **AUC-ROC of 90.12%**, meaning good class separation

â¡ï¸ This makes it **practically useful** for real-world anomaly detection.

---

## ğŸ“‚ Project Structure

ğŸ“ src/
â”‚ â”œâ”€â”€ preprocess.py # Dataset loading and cleaning
â”‚ â”œâ”€â”€ xgboost_model.py # XGBoost training and evaluation

ğŸ“ data/ # Large CSVs ignored in GitHub
â”‚ â””â”€â”€ raw/ # UNSW-NB15_*.csv files
â”‚ â””â”€â”€ processed/ # combined_cleaned.csv

ğŸ“ models/ # Trained XGBoost model
ğŸ“ outputs/ # Plots, confusion matrix, metrics
â”œâ”€â”€ requirements.txt # Install dependencies
â””â”€â”€ README.md # You're reading it

yaml
Copy
Edit

---

## ğŸš« GitHub File Limit Note

Due to GitHub's 100MB file limit, large CSV files (`data/raw/`, `data/processed/`) are excluded from this repository.

To reproduce the project:
1. Download the [UNSW-NB15 dataset](https://research.unsw.edu.au/projects/unsw-nb15-dataset)
2. Place the 4 `.csv` files in `data/raw/`
3. Run:
   ```bash
   python src/preprocess.py
   python src/xgboost_model.py
âœ… Summary
This project proves that:

Accuracy is not the right metric for imbalanced anomaly detection

F1 Score and AUC-ROC are better reflections of model quality

XGBoost can detect intrusions with high precision and recall even in real-world, noisy, imbalanced network data

